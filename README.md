# NadoAI


# Telegram Бот Техподдержки для RuTube
![rutube](https://habrastorage.org/getpro/moikrug/uploads/company/100/004/548/2/logo/medium_aee8d387f1dd8d0ef2ea7380c4b3bb26.jpg)

Этот проект реализует Telegram-бота техподдержки для платформы RuTube. Бот принимает вопросы от пользователей и отправляет их на сервер с моделью машинного обучения для получения предсказаний и автоматического ответа на часто задаваемые вопросы. Сервис на основе Flask обрабатывает запросы и возвращает ответы, классифицируя запросы по тематическим категориям.

## Структура проекта

Проект состоит из двух основных сервисов:

1. **ML_service** — сервис на Flask, который отвечает за обработку запросов и определение ответа с использованием моделей машинного обучения.
2. **TG_bot** — Telegram-бот, который взаимодействует с пользователями, отправляет вопросы на ML-сервис и возвращает ответ пользователю.

## Функционал

- **Telegram Бот**:
  - Получает сообщения от пользователей.
  - Отправляет вопросы на ML-сервис.
  - Возвращает предсказания и ответы пользователю.
  - Легко модифицируем для интеграции с другими службами поддержки.

- **ML-сервис**:
  - Работает на Flask и Gunicorn.
  - Использует `SentenceTransformer` для обработки и сравнения вопросов.
  - Поддерживает классификацию запросов по уровням поддержки.
  - Отвечает на запросы по REST API.

## Используемые технологии

- **Python 3.11**
- **Flask** и **Gunicorn** для ML-сервиса
- **python-telegram-bot 20.x** для Telegram-бота
- **scikit-learn** для обработки текстовых данных
- **SentenceTransformer** для векторизации и сравнения текстов
- **Docker** и **Docker Compose** для контейнеризации и управления сервисами

## Установка и запуск проекта

### 1. Клонирование репозитория

Сначала клонируйте репозиторий на локальную машину:

```bash
git clone https://github.com/PaukIsUha/NadoAI
cd NadoAI
```


## 2. Структура проекта
Проект разделен на две папки:
```bash
/project
    /ML_service        # Папка с ML-сервисом
        Dockerfile
        requirements.txt
        main.py        # Основной файл для Flask-сервиса
        model.py       # Основной класс модели для инференса
        models/        # Папка с весами моделей
    /TG_bot            # Папка с Telegram-ботом
        Dockerfile
        requirements.txt
        main.py         # Основной файл Telegram-бота
        configs.py      # Конфиги телеграм-бота
        database/       # Папка с базой данных для истории и дообучения RL 
        
    docker-compose.yml # Файл для управления контейнерами
```

## 3. Сборка и запуск контейнеров
Для запуска двух сервисов используется Docker Compose. Убедитесь, что у вас установлен Docker и Docker Compose.

Соберите и запустите контейнеры:
```bash
docker-compose up --build
```

## 4. Описание сервиса ML_service
Сервис работает на Flask и доступен по адресу: http://localhost:5221.

Основные эндпоинты:

GET / — Тестовый эндпоинт, возвращающий статус сервиса.

POST /predict — Основной эндпоинт для предсказания, принимает запросы в формате:

```bash
{
  "question": "Ваш вопрос здесь"
}
```
Пример ответа
```bash
{
  "answer": "Ответ на вопрос из базы знаний",
  "class_1": "Классификатор 1 уровня",
  "class_2": "Классификатор 2 уровня"
}
```

## 5. Описание сервиса TG_bot
Бот взаимодействует с пользователями и отправляет запросы на ML_service.
Убедитесь, что ваш Telegram Bot настроен с правильным токеном.
При запуске контейнера, бот автоматически начинает слушать сообщения и реагировать на них.


